**Simon Wang:** Alright, so, we are in week 4 now for our course, and, before we get started, I just want to invite all the students to, log in with your HKBU credentials, so you will be able to have access to this page. And not every student will have access to this page. By default, I think only the students from science faculty, will have access to the API key. But I submitted your name to ITO, so you should be able to access this page as well. So very briefly, I want to explain what is API. API stands for Application Programming Interface. Which is a different way to communicate with the computer system. The more conventional, typical way of Communicate with the computer system is through what we call graphical user interface. Like what you can see now. So, you see there's some graphics, and you enter, you type some text. And you will be able to communicate, and the chatbot will respond in a graphical user interface. But the application programming interface is, a different interface in the sense that, we do not use this kind of, GUI, or graphical user interface, instead of we write codes. And, through the codes, and we, following the protocols and rules specified in the API, so that Our computer program can communicate with a computer system, like large language model. Now, the reason we need you to grab this key is because later on, you need to enter the key into a platform that we built. And this way, our platform will be able to leverage the ITO's platform, and Because, you know, tokens are not free. You know, that's the basic fact. The fact that whenever you talk to a large language model, somebody has to run the computer somewhere to process your response and to run the model. So, tokens are not free, and ITO actually bought a lot of tokens from Microsoft Azure, and therefore, each of us can access the HKBU General AI services. Now, when you got the API key, and you enter to our system. you will be able to use the token from HKB UITO allocated to you. And, and then you can enjoy the services, okay? So I hope that's… clear enough instructions or explanation. If it doesn't make sense to you, that's okay, because you don't have to understand everything in order to use it, right? So all you have to do is just come to this page. and generate the API key, and remember, once you generate the key, you have to keep it somewhere, okay? Because it will show once only. And I'm not going to generate my key again, because I already generated before. So, go ahead and do that, and keep it in a place that's safe, okay? So, any, any question? So take some time and, get your key. I think I need to find mine as well. Now, Okay, I think, we should officially get started. We've got 27 students here, which is great. Well, again, I just want to very briefly talk about… because today, the reason why we are, we are having this, online meeting is because Typhoon, so I want to very quickly, share with you two letters that I… I published a while ago. about Typhoon, so… because, in this course, we're trying to… look at the government's decision and how data is being used to inform the government decisions, and we don't just do things within the classroom. This is an experiential learning course, so we actually want students to experience something different, something that you don't typically get in a university classroom. So… One thing that I hope some of you can experience is actually if you write letters to South China Morning Post, because this way you will be able to voice your opinions, you're going to join a conversation about public policy. So here's one example. If you still remember, I don't know whether you remember, this was a letter published Beck… In 2018, when there's this typhoon called, Menkok, so, rumor says that, you know, the coming typhoon is as strong, or even stronger than this one. But look at what happened, the day after typhoon. You know, people get stuck in this, in this, MTR station in Taiwai. And, I was… I was writing, you know, I wrote this letter to argue that actually, we should consider Allowing people to take a break after the typhoon. In case, you know, the city, you know, needs some time to recover. So, so that's, that's one, one… letter I want to share with you. And I think it's important to take a data-driven approach to this kind of decision-making. I don't know whether the Security Bureau or the Office of Chief Executive has been reviewing this case. I hope they have learned a lesson, because in terms of data-driven approach, we should definitely look at the whole, you know, transportation network, the infrastructure, to what extent there's damages to the system that the city needs time to recover. Right? So, so that's… that's a very important, case we want to, we want to consider. In fact, we have one team who's going to work on Typhoon, this semester, so I hope that team can also take a look at, this, this issue. Now, another letter I want to share with you, it was published in, last year, actually, 2024, Because starting from last year. the Hong Kong stock market will actually operate as usual, even when there's a typhoon. So, this, this is a new, new arrangement, starting from last year, and the argument I was trying to make is that as the title suggests, if the Hong Kong stock is changed. Could operate as usual, you know, because people work from home and, etc. then everybody should be doing that. Knowledge workers, schools, universities, we should all just, work as usual, you know, even during the typhoon days. But, unfortunately, at this stage, the Education Bureau the universities do not really have any official policies over how work should be arranged during the typhoon days. So again, if we think about data-driven approach, if we think about how we can help the government to make better decisions, then we need to start thinking about how to collect the data, how to use the data to, inform the decisions, alright? So, you know, because of today's timing, I just want to kind of share with, two, essays that, I published it a while ago. And another quick update is I've created Google Drive folders for each team, because I think right now we've got six teams. Each team has already selected a specific topic, so we're kind of ready to move on, to start actually working on the projects. So, anyone who is not yet in a team. or anyone who cannot access to the Google Drive folder that I share through the small WhatsApp group. please let me know. You can send a message to the small WhatsApp group, you need to give me your Gmail account. In fact, your classmates, your groupmates who have access to the Google folder, Google Drive folder, they should be able to invite you to access the Google folder. Alright? So, within the Google Drive folder, you will be able to see a couple of Google Docs. Okay, so all these Google Docs are empty at this stage, but just to kind of quickly go through this… We will have a meeting notes page. Basically, whenever we meet, whenever we have any progress on the project, you need to update the meeting notes, and you probably want to meet with your teammates from time to time to, you know, start working on the project, then you should update the meeting notes. We have a data collection plan, because, Next week, we're going to have small group meetings, and the week after is actually public holiday. So you should take the time to… the whole week, to doing some data collection. So, that page, that doc, is for you to update records about data collection. And there's also a worksheet, this is just a spreadsheet for you to, in case you want to have, put some structured data in that sheet, you can do that. We have a project report. document, that's where you can actually start planning your project report. This, this document, I think I'm going to rename it because, you know, on a second thought, I think this document should be more about outreach and presentation, so I'm going to rename it later. So basically, this Google Drive folder is where you want to do some real work, and you want to move forward. And just one quick reminder about doing everything is you want to document your contribution, okay? So whenever you're updating the document, whenever you are making some efforts to move the project forward, write down everything you have done with your name on it. Okay? Because at some point, we will start reviewing, everybody's work, we want to make sure that everybody contributes fairly to the teamwork, because part of the… I think about 50% of the whole course grades is by groups. But, we definitely want, you know, students to. contribute, and we enjoy teamwork, and we work together. So, it's very important to keep record of everything you do. In, in this space. Alright, and both Taylor and I, we have access to this space as well, and feel free to raise any questions, you can add the questions here, and then you can, you know, send us the link through the WhatsApp group or email us, and basically, this is going to be the platform where we're going to do the collaboration work. Okay, so any, any questions, any concerns, just, let us know. And this is actually a website I built a bit earlier, you can check out. It's kind of fun, because we use them API to access the data from Hong Kong Observatory, and we update this in real time, so we'll be able to see dumb, the wind data from the 30 stations And to see whether… to what extent the real, wing strings actually align with the signal number that the observatory published. But I won't get into details, because that's… basically the project of one of the teams. But just for fun, because you can see that the storm is coming, and we should be able to look at the data in real time. Right? Now… Before I invite, Taliet, you know, for Dr. Wu to talk about simulation, which is the main focus of today's topic, today's work discussion, because last week we talked about regression, this week we talked about simulation, there's a little bit more, in-class exercise we're going to work on. I want to talk about reflective essay. Now, a reflective essay is one of the assessment components. It actually accounts for 20% of the final grades. There's a total of 3 reflective essays you need to write, and this essay is not very long, it's only about 200 words. And one of the, kind of, the special features of this course is that you can use AI to write an essay. So we have some AI chatbot. that can help you, which is the reason why we invite you to set up the API key from the ITO page, right? So, if you come to this Moodle page. you will be able to see there's the reflective essay assignment. The deadline is, about two weeks from now, okay? So, there's a little bit of time you can work on, so just take your time, and you don't have to submit it just yet, so any question you may have, just let us know. The way you submit this essay is just to reply, okay? So you reply here. And you can submit your… Your essay. Now, actually, you can read through this Moodle, so a Moodle page, so I'm not going to get into everything, but just one thing to highlight is that we have this Page. This is where you can actually, talk to an AI, okay? So we have this AI writing assistance, as you can see. You need to reflect on what you have learned in the past 4 weeks or so, and also you want to start thinking about the project, alright? Because in the past 2 weeks, well, including this week, The main task we're trying to teach you, well, especially Italia, is trying to teach you some tools, okay, for quantitative reasoning. We talked about regression, last week talked about… we're going to talk about simulation. And once you learn a little bit about these tools, you need to think about how these tools will be applied to your projects. And while you're doing that, you can start writing this refractive essay, okay? So… As you can see here, there's a little bit of information, and you can go back to the Moodle page. But then… how do you use the tutor? Well, basically, you need to get your key. And then you click here, That will give you… get you to the… the tutor page. This is iframe, so it takes a while to load. And, here is where you want to enter the key. Okay, let me see if I got my key. So you got your key. And you choose your model, usually 4.1 would be good, and then you click connect. Now, once you click connect, you get connected. Right, and then there's some system prompt here. There's a welcome prompt here, it says, You know, This is your tutor for the course, you need to write a short, refractive essay and everything. And said, type OK to get started, then you type OK. Okay, and then the tutorial will start talking to you. Great, let's get started. Thinking about your team project, where were your… the key decisions made by the government that your team plans to focus on? Remember, we have this post that we talked about a while ago, we talk about, like. the group project instruction and timeline, I think we talked about this in week 2 or something. So, last week and this week, we explored topics, we talked about the tools, and next week, when we do the group consultation, we need to you know, finalize the top… I think everybody already selected topic, but then we have to start working on it. So go through this page, And then you come back. And you can start talking, so something like, maybe you can just, use an example. whether… to… Hello, people. To take a day off after. Typhoon. So just, just, just as an example, okay? And, and, you have a conversation with, with the chatbot. and go, and so on and so forth, and then your teams look at this, think about the data, right? How did the government use the data to inform the decision, blah blah blah. And you can say what… You can say something like, what would you suggest? And also you can close this if you want a bit more space. Okay, and then you can, you can start, ask the chatbot about… the model and everything, okay? But just to remember, AI can hallucinate. You know, AI is not 100% reliable. So part of the skills you need to learn in this course when you interact with AI is to be critical. Okay, don't just take anything that AI says as correct, or as completely reliable, alright? So you keep going like this for a little while. And then you click this green button. Well, actually, at some point. You know, the chapel will start… guide you to write an essay. But if you say, can you write… the essay. Well, actually, when you say, can you write an essay for me? The chat will probably help you to write an essay. But remember, you still have to put a lot of thoughts into it, okay? Because, because what we're trying to do in this course is… Okay, so actually, they write an essay for you, you see what I mean? But that's not… clearly not what you want to do to just submit it to the Moodle, right? So you actually have to put more thoughts and everything. But again, when you click here. You got… You got a, a page. Where you can, get a chat history and a little bit of analysis of what you have done. And, you, you can put your ad… you can put your email here, because… We don't have a login system. once you close the browser, everything is gone, okay? So, before you close your browser, make sure that you… you click the green button here, green check, and then you email. Alright, so, so you will get an email copy. Of the chat history. And your teacher will also get an email copy of the report. And if you want to download. You can also download the Markdown or PDF. Okay So that's the… that's the platform we built to help you, okay? So I hope you will enjoy it, I hope it's a good experience for you, because we believe that AI is going to be the partner for all of us, you know, especially when you become a knowledge worker after you graduate. So we want to create an authentic learning experience for you, that's why we have this AI platform for you to try, and… And just a kind of disclaimer, the platform is relatively new, and there could be some glitches, some, you know, bugs and everything, so please be patient, and do let us know how it goes, and try to keep a record of everything you do, just in case you, you know, close the browser or something, or the copy may not… the email function may not work properly, then download the Markdown, or download the… the, PDF before you hit the send button and before you close the browser. Alright, so I think that's all I have to say. Any questions? Remember, in the Moodle forum, we actually have one post for each topic. I think the information here is still useful. You do want to come back to kind of learn more about how this, project, you know, how you should pursue this project. And we have the smaller WhatsApp group for each team. we should work very closely, through the WhatsApp group, and, you know, you guys may want to, you know, set some meetings, and, because, you know. I think the goal is for us to… Send off inquiries to, to the government, around, next week. So you need to start thinking about that as well. And we're going to have another chatbot to help you with that, but for now, this chatbot for writing reflective journal, a reflective essay, should be a good start, because you only take the opportunity to reflect on what you have learned, and also to think about how you move forward, with the other… with the projects. Okay? So, any, any question? I think a good place to start is actually… this Moodle page. Because… I think this is the page where… You should have everything. I saw some message on the chat. Oh. Oh, okay, so I think I need to update the Moodle page about the deadline, because we kind of extend the deadline a little bit, so, Yeah. So, one question about the Moodle page, I think I need to update that. I think the deadline should be October 5th. What should invite accounts says it's not eligible to use the API service. I think you have to log out and log in again. Because the… ITO colleagues told me that they have already updated the records, so all the names that I submitted should have access to the API service. If you cannot, you log out, and then log in again. If you still cannot access the page, just email me, and I will follow up, because I'm sure that I submitted everybody's name. Any other… Questions? Okay, so… I think, that's all I have to say. I'm going to pass the floor to Talia to talk about simulation.

**Tian WU:** Okay, so good morning, everyone. Can you hear me clearly?

**Simon Wang:** Yeah, okay.

**Tian WU:** Okay, so, can you see my screen of the Moodle page? We're seeing…

**Simon Wang:** VS Code.

**Tian WU:** Let me share my screen again. So now should be the Moodle page, right?

**Simon Wang:** Yes.

**Tian WU:** Yeah, okay, so before I started the, explanation, I would like to remind you that I updated the, Jupyter Notebook for the regression part. And I also uploaded a new joker notebook, which is called the Box Whisker Plot. And also, we have the simulation notebook for today's demonstration. So these are the three documents you may download. So later, we will discuss them one by one. And before I start, talking about the simulation, I would like to follow up on the last in-class exercise, which is about some data visualization you worked on. Let me share… Okay, so now my shared screen should be the, VS Code. Page Wright. So last time, at the end of the in-class exercise, I invited you to do two visualization tests to explore the relationship of, That might be interesting. So recall that the data set we used is the municipal solid waste dataset. Where our response variable is the level of support for this policy. And the potential explanatory variables, including the demographic variables, attitude-related variables, and behavior-related variables. And when I received the in-class exercise. This is the typical visualization result I get. So you can see for the first visualization, it is about the support level versus the perceived fairness of the policy. But what you would observe are these, separated dots. It is because, for fairness and the support level, they're both categorical variables. they can only take values like 1, 2, 3, 4, 5. There's very limited and discrete integers. Okay. So all the possible combinations are shown by these dots. But this is not that informative, given that these two variables, they are categorical. So I think a better way to do it is… Then open. The latest regression… notebook. So here, it's actually used the bar chart. To show, in different categories of perceived fairness. What are the percentages of opposed, neutral, and support? So to do this, we can first record the, strongly against and against as opposed. And we code very strongly support and support as support, so we will overall have these three groups. And then… Show the percentages of these three groups. In different categories of this perceived fairness. So if we… show… Again, the two variables in this way, we can easily observe the trend. With the increase of the perceived fairness of this policy, The percentages of a post decrease. Right? The blue bars, the height, decreased. Whereas for the height of the green bars. The percentages of support is increasing from, like, 11% to 75%. So the message is that if the variables themselves are categorical. Then, it is better to use bar charts. And using percentages. To represent for different categories. The percentages of different, groups. For… for the other categorical variable. I think for this, figure, it is… More informative compared to these dots. Right, hopefully you, agree with me. So when we do the visualization, we need to consider the type of data. So then, when we use this scatter plot. Well, when the variables are continuous, it is more often to use the scatterplot to show the relationship between the two variables. So I think in the demo. We once used the, scatter plot to Let me find it. So now I'm at this regression model's full notebook. Yeah, here. So this is not a good example, but at least the, one of the variables the distance between home and the nearest facilities. This is a continuous variable. And for this scatter plot, we can see whether, on average, with the increase of the distance between the home of the participant of the survey to the nearest Recycling facility, whether their support level is increasing or decreasing. So most of the time, we use Scatterflow to measure or to visualize the relationship between two continuous variables. This is the first message. And the second is about the, plot. Showing the education level versus the level of support. So again, education level is a categorical variable. Right, it can only take these discrete values, 1, 2, 3, 4, and we know the larger the value, it represents the, respondents has, a higher education, higher level of education. So again, if these two are both categorical, a more appropriate way to visualize the relationship should be, again, the bar plot, showing the percentages. In each, there's different, level of education, the, percentages of the, against, neutral, and support. And here, this plot is actually a box whisker plot. And this is usually used to show the distribution. Of a continuous variable. So I will give, a numerical example to… To show you what does this box mean, and what this whiskers mean. So now let's move to the box whisker plot. I mentioned this notebook in the Moodle. So suppose I have this sequence of values, So I generated these values. In total, there are 26. And they are, capped as two decimal places. And it is already sorted. So the smallest is from 0.15, and the largest is from 4.85. to generate the box whisker plot. We need to calculate the so-called five-point summary statistics for these data points. Specifically, when you find the minimum value, which is obviously 0.15, And also the maximum value, which is 4.85, right? And for the middle 3-1, They are median. So the median basically means the data points were cut the whole data set into two parts. So the first 50% of the data, their value will be smaller than the median. And the remaining around 50% of the data, their value, will be greater than the median value. So, in our dataset, Given that there are 26 values. So there will be two values sitting in the middle. Which is the, 13th 13th data, and the 14th data. For each role, there are 5 data points. So, the 13th data point is here, and the 14th data point is here. And the median will be the average value of the two data points. So we take average of these two, and it is 0.8. So here, originally, the data points are not exactly two decimal places. So after some rounding, we have this 0.79 and 0.8. And after we take average, and again, doing the rounding, the median is 0.8. So this means that if we have a Like, you imagine that if there is a, little vertical bar here. This is the first 50% of the data. Given that This data is already sorted from the smallest to the largest. Whereas the remaining ones are the later. So from here. These are the later, or the largest, the 50% of the data. So this is what this medium means. And in the box and whisker plot, this mean is usually shown as the, the horizontal bar in the middle of the box. So if we go back to this education level. you see this horizontal line in the middle of the box? So this is the median. Median value of the, of these data points. But we also need to decide the, where this, edge of the box is. So there are two edges, the upper one and lower one. And we need to decide, what this corresponding value is. And to do that, we need to calculate the so-called the Q1 and Q3. So it's the, quartile one. So this is the, value in the dataset that will split The first 50% of data, again, into two parts, So, 25% and another 25%. For example, for this data, we know that for these highlighted values, These are the first, like. 50% of the data, right? 13 of them. And then the value sitting in the middle will be the 7th data point. So in total, we have 13 data points. And the seventh data point will split the certain data points into… there are six, data points. Before, there's 0.57. And another 6 data points after this 0.57. Within the first half, of this dataset. So then the Q1 value will be 0.57. Whereas, similarly, for this Q3, we focus on the, the median of the Later, 50% of the data. So here is the later 50% of our data. And we just count the 7ths, 1, 2, 3, 4, 5, 7. So this… this 1.64 will split The later 13 data points into two parts. 6 before it, and 6 after it. So this is the, Q3. And with this, 5… point, summary statistics, we can decide where the box is. So if I scroll down a little bit. You can see that on the right-hand side of this figure is box and whisker plot. In total, there are 26 values, all are kept as two decimal places. The median is shown by this green line. The median is 0.8. So you can find the corresponding value here. And for the edge of the box. here is the value of Q1. So we calculate the Q1 is 0.57, This value is around 0.57. And the upper edge of this box The value is 1.64. So here. The corresponding value on the y-axis is 1.64. And we also have this minimum and maximum value, so the minimum value is 0.15, which is the end of this whisker. Whereas… The maximum is 4.85, It is flying out of the, the whisker on the top. So then, how do we decide which values are flying outside of the range? Well, this is decided by calculating the so-called inner fence, So the inner fence. depends on the IQR, where the IQR is the Q3 minus Q1. In this graph, the IQR represents the height of this box. Right, because here, this value is Q3, and this value is Q1. So if IQR equals to Q3 minus Q1, It represents the height of the box. And the lower fence is calculated by the IQR minus 1.5. times… Sorry, Q1 minus 1.5 times IQR. So the formula It's shown in the code. Here, for these three lines. Because there's no, predefined formula to calculate the IQR and also the so-called lower and upper fans, so we have to manually calculate these values. So previously, we have calculated the value of Q1 and Q3, and we also know how… how tall that box is. So we can just substitute the value and get the inner lower fans and inner upper fans. So, after calculation, we found the lower fence is negative 1, and the upper fence is 3.2, As long as the data point Is lying out of the range. From negative 1 to 3, then we will define the data points as outliers. In our dataset, There are 3 values. That are greater than this upper fence. So you will see the corresponding three data points. Flying out of the range of this box. And whisker plot. And the… the end of this whisker Will… will be the largest value in our dataset, which is not ex… exceeding the upper fence. So here, the, the end of this edge is, like, 2.15. And as I mentioned, this box plot is used to visualize. First of all, must be the continuous variable. And also, we can use this box plot to have An intuitive understanding of the distribution of the data points. For example, we know that there are some extreme values on the… on the large value. So there must be certain extreme values. For… for large values. Correspondingly, on the left-hand side, I plot the histogram. Which… Divide the range of this dataset into different intervals. and then I count the number of Values fall into different intervals. So, for example, here, I think this is around 0.3, so from 0.3 to 1.2, For… for the value. In our data falls into that interval. we count the number of values. Say, in total, there are 16 such values. Then we have a, a bar. Here. And then we count the number of, values falls between one point 2 to 2.1. And it turns out that there are 6 of them, so we have the second bar, so on and so forth. And it is indeed that we found there is a bar, so there are 3 values. falls between, like, 3.8 to 4.7. So there are, three values. Which are really large. So that corresponds to this outliers on this box plot. And also, we can pay attention to the distance between Q1 and median versus the distance between median versus Q3. We know that in this box. There are 50% of the data. Right, the middle 50% of the data. But for the lower 25%, Their range is relatively small. Compared to the range of the other 25%. So this means that Starting from this median level. The range of the next 25% of the data is Bone. Larger. Compared to the previous 25%. So… If we look back into the histogram, this is reflected as a, sliding. It's like a slide shape in this histogram. So on the left-hand side, the distance is relatively short. Whereas, on the right-hand side, the, the distance is… It's larger for same 25% of the data. So you would imagine that if we can, have more data. So that the histogram will become smoother, then here will be a, here will be a, peak, and then gradually the shape will slide down. And given that there are some Large values on the right-hand side, there will be a long tail. Extending to the right. So with the tail on the right-hand side, this is called a scale to the right shape of the distribution of this dataset. So roughly, we can see from this, box plot. About, whether there's an outlier. And the range of most of the data, and also, somehow, the distribution of the data points. I think this shape is a bit like when we discussed about the, the salary… So we know that, there are many super-rich people in Hong Kong. And if we calculate the average salary of all the people in Hong Kong. The average will be inflated because of those very rich people. Right. So, the mean value, the average salary, will be… Extract to the right. Due to those very rich people. But for most of the people, if we consider about the median. The median level of the salary, like, 50% of the people, their salary will be less than this amount. And the remaining 50th percent will be greater than that amount. So this… Media will be… Smaller than the average, than the mean value, if there are some very large value on the right-hand side. Because median is not that sensitive to the extreme values. or the outliers, because it's considered the center. It cuts the data points, in the middle. Whereas for the mean value, when we calculate mean, we need to Sum over all the points. The value of all the points in all the data points, and then divide it by the total number of data points. Then, this mean value will be, Dragged to the right. because of these extremely large values. So we observe this mean value sitting At the right-hand side of the median value. Or if you translate to the box plot, then it is above. The, median value. So hopefully, with this example, you have a better understanding of this box and whisker plot. And, you could use all this visualization under appropriate circumstances. Okay, I think maybe we take a 10-minute break, and if you have any questions, you can just send message in the chat box.

**Simon Wang:** So while we're taking a break, if anyone cannot have access to the Google Drive folder I shared in the individual WhatsApp group, just send your Gmail account to the group. And you know, actually your group members should be able to help you, invite you over to the folder, but you need my help, you can also, tag me and let me know. And also, if you, need help regarding the API key, also let us know. I think after, you know, after the break, Talia will talk a bit more about simulation, and then we're going to, have the in-class, exercise. And I'm going to set up some breakout room, so the… group members of each group can go to the breakout room, and, you can talk there, you can actually have a meeting about your project while you're doing the in-class exercise. So… Because next week, we're going to have small group meetings, We're going to provide more instructions in terms of the arrangement, But, Next week will be very critical, because you need to make some progress over the… over your own project, and you have to decide how you want to approach the government to collect information. So, and also this is the week before the public holiday, and you want to think about how you want to collect your data. So, so a lot of decisions will have to be made, Hopefully before or during. the group meetings next week. So I think we need to kind of… in addition to learning about the models, we need to start thinking about how to apply the models and tools to our projects. Right, another quick, message about, about Gihub. is that since you already took some time and efforts to learn about GitHub, VS Code, and everything, I would encourage you to actually apply for the GitHub education, because, once you get the GitHub education, eligibility, you will be able to enjoy some, GitHub Copilot Agent services, which is usually premium services that you have to pay, but if you've got student benefits, then you can use it a little bit more for free. At some point, we're going to talk about that. Well, we don't want to overwhelm you with all kinds of technical, details, but, I think the agent is going to, you know, give you a lot of, opportunities and, you know, help. So I would encourage you to look into that, but you have to apply for the education benefit first.

**Tian WU:** Okay, so maybe let's resume. So Simon just mentioned about the GitHub education. If you log in into your GitHub account under this Billing and Licensing. education benefits, you can go to this GitHub education page to submit an application. So on average, it will take around 5 days to process your application. Okay, so regarding this box and whisker plot, if you ask the AI's help to generate this plot based on certain data, then the plot will be directly out. So you don't have to actually consider all of these details. But the reason I explain it is to hopefully help you to have a better understanding of how this is plotted out. And another point is that if you would like to change the setting of the code. Say, if you want to plot 30 data points, generate 30 data points rather than 26, Of course, you can tell the AI assistant to help you to modify the code. And you actually don't have to copy and paste, because there is apply to this notebook. So once you click this, So the corresponding, code will be modified automatically, so you can see the old version with 26, and the new version with 30. So just click keep, if you think everything's fine, just click keep, so that it saves you the copy and paste. You can Directly apply the modified code to the old version of the code. Okay, so this is a tip. Okay. So then, I still have some last words about the, requestion? Yup. So last time, we mainly talked about the linear regression, and our purpose is to try to use our data to estimate the values for this beta zero, this intercept, and the slope term, the beta 1. And that is the case when the response is a continuous response. Which means Y should be a continuous variable. But in reality, it is not always the case, right? In our questionnaire, the response variable is actually categorical, from the strongly opposed to strongly support. In that case, it is not that appropriate to apply the linear regression, because it already violates one of the assumptions of the linear regression for distribution of the Y, or for this error term. So, based on different types of responsible variable. If the response variable is binary. Like, when it can only take value of 0 or 1, We will have the so-called logistic regression, And if Y is categorical, Especially… It's an ordinal categorical response, just like in our questionnaire is from strongly opposed to strongly support Then it is more appropriate to use the ordinal regression. Because not all of you will, will make use of, regression, because, as mentioned, regression is only, Appropriate to be used to model the relationship between a dependent variable and one or more independent variables, assuming a linear relationship. So if the question type is. We want to explore the relationship between the response and some potential influence of factors, then linear regression might be a useful tool. But not all of you will use this. So I will not, spend more time to talk more about the details of logistic regression and the ordinary logistic regression. But later, if your group project will make use of regression models, then we can, in a small group. I will talk more about this, correct interpretation of the, the parameters for logistic regression and ordinary logistic regression model. So that's the final words for the regression models. And then, finally, we can start with the simulation. So this is our second, This is our second case study. The topic is to evaluate the efficiency of the bus road adjustments. City bus number 56. Thanks. So here comes the structure of the case study. We'll first briefly talk about the background of this proposal of adjusting the bus frequency and road. And also, briefly introduce the simulation design. And look into the random component in the simulation, and how we interpret the results, and correspondingly, how this study will help generate certain questions that we can acquire with the transport department. Then we will have the in-class exercise. So, background. Actually, every year, this is an annual exercise for the franchise, the bus companies. to submit these bus road planning programs to the Transport Department. So… Do you know how many, franchise the bus companies in Hong Kong You can type in the chat box. 2? Actually, there are 4 bus companies. So the franchise, the buses, including the city bus, the Colon Motor Bus. Long Wind Bus and New Lentell Bus. In total, there are 4 franchise bus companies in Hong Kong. And after they proposed this road change to the Transport Department. The department will review the proposal and consult with relevant district councils. Particularly for major changes, because that will affect the residents in the district. So they will, consult the, district councils, About the adjustment. Then, this proposal will be implemented, often begins on a temporary basis. Following up to 24 months of operation without permanent legislative changes. And if this change is determined to be a permanent change, Then, legislative procedures are required. When the road changes need to be made permanent beyond the 24 months temporary period. So that's the overall flow of… from proposing the road change to, finally, we have certain legislative procedures. And in our case study, we will focus on city bus number 56, So it is, operating in the North District. So you can actually find that this, proposal is discussed in the committee meetings in the, North District Council. And in this proposal, it states the criteria for increasing the buzz frequency. Specifically, our case is, cited from the 2024 to 2005. This bus road planning program. It says that for individual bus roads, if the passenger load factor reaches 90% during the busiest half hour. And 75% during the busiest hour of peak periods. Or 60% during the busiest hour of off-peak periods. Then, the department and the franchise, the bus company, will consider increasing the service frequency. So this is written as the criteria for increasing bus frequency. But… I think… here, sorry that I cannot find the Chinese version of this, this proposal. It seems that only the traditional Chinese version is provided. But for this 56, Regarding the, capacity of passengers, It says that in the In the busiest one hour, The passenger load factor is 32%. So this is before the adjustment. They will make, adjustment of the frequency of 56, so that the existing capacity. will be improved. But it's a little bit weird that we found that for this bus number 56, Even before the adjustment, the so-called passenger load factor is only 32%. So then that leads to the question. It is unclear, first of all, it is unclear how is this passenger load factor is defined. So if we only consider those, stating passengers. Then that will be the seed utilization rate. Like, we use the number of people. on the bus. Divided by the capacity, or the number of seats on the bus. Then we can have this, seed utilization rate. Or, it can be, like, we use the number of people on the bus. To divide the total capacity of a bus. Including… In those standing spots. So then, in this proposal, it is not clear exactly how this passenger load factor is defined. Which way? This is calculated. And specifically, for this number 56, when the business hour occurs. So I bet for a different, bus road. The busiest hour will be different. Right, but it is not listed here. It only lists the, the frequency of the bus during the busiest hour, but it does not mention when exactly the busiest hour occurs. Also, we only have one single number for this passenger load factor. And we… by imagination, we… we… we can… We can see that for different stops. The seed utilization rate will be different. Say, for those bus stops, which are near the MTR station. If it is before the MTR station, I would expect that The seed utilization rate will be high because I would bet people taking this bus to go to the MTR station. And after the bus arrives at the MTR station, people get off the bus. And then the seed utilization rate will decrease. So for every stop, these numbers should be different. And also, For different time period. As is mentioned, there are business hours, right? So for different hours, these… Seat utility rate… utilization rate should be different. Say, during the morning hours, during the lunch hours, It should be certain variation. So then, how exactly this single number is calculated? is not clear. And also, how an increase in bus frequency is justified. Given… These percentages is very low, actually. Comparing to the criteria in the same document, it says… it says that When this number reaches… 90%, then the company and also the transport department will consider increasing the service frequency. There are many questions. After we reach this proposal. So specifically, Originally, the, city bus number 56, the road is from the road is the, the… represented by the blue line. Blue… blue curve. So this is from… turn on to so-and-so. this blue… Curve. And it turns out that In addition to the frequency change, the rate of this, this, Buzz also changed. So now it is the, the rotis represented by this red dashed line. So, visually, it's the distance of the, overall overall distance is increasing. So we can see some key summaries of the Of this bus before and after the adjustment. So before, the, adjustment… The total distance for the forward direction from Timmun to Shenzhou is 26.9 kilometers, whereas after adjustment, the distance is longer. Whereas for the service time, it is increased by adding this afternoon to night session. Plus the weekends. And the hard way, which is the frequency of the bus. So, previously, before adjustment, in one hour, there will be 30, there will be 2 buses. Whereas for the proposed change, which is now, in action, it's like in one hour, in the morning sessions. There will be 3 buses in 1 hour. Although the road is different, the number of stops is kept the same. Whereas for the return direction, the overall distance increased. The overall service time is increased. Like, adding the, afternoon and night session, plus the weekends. The frequency is kept the same, and the number of stops increased. So that's the overall, background for this bus. And our objective is to develop and analyze a simulation of the bus road 56 operations during the morning. Using field data, and also the estimated arrival times. It's called ETA, from the Data Gulf of Hong Kong. So pay attention that this bus starts service after 9. So I think this is already different from the peak hour we usually define. If we consider when the students go to school and people go to work, then usually the peak hour will be, like, from 7, or even from half past 6. But for this boss, It does operate. ads. At least after 9 o'clock. So we want to test, with the change of the frequency and also the bus route. How would this seat utilization rate change using the simulation method? And then we can provide the evidence-based policy inquiries to the transport department. So recall that, we introduced this If you have any comments, you can maybe type in the chat box. So we talked about this simulation design in the, first class. We said there are two tools will be introduced. The first is simulation design, and the second is regression. So, simulation is about mimicking complex systems, Normally, over time, using logic, Maths and computers. So today, we will have a, kind of, intuitive understanding of what this means. And simulation is an experimental process. We run and rerun the model many times under different scenarios to predict the system behavior and evaluate performance under each scenario. Previously, I have shown this, simulation visualization. So, we have the, clock, which is… Record… which is recording the time passed by. And say, at 9-10, the first bus set out. And for each station, there will be passengers queuing. And of course, we will have the passengers alight the bus, so the number of passengers on the bus will not keep increasing. So at some point, the number of passengers on the bus will decrease. So this is the, visualization of the simulation. So we can have a real-time calculation of the utilization rate by different bus stops. So this will keep changing with the clock time past. So then, let's see how this is, implemented. So, in our simulation, There are 3 random components. And this will, these three random components will affect, the seed utilization rate, which is the KPI we focus for this Simulation. So to calculate the seat utilization rate, we need to count the passengers on bus at each stop. Right. But this number is affected by this three components. The first is the travel time between each pair of stops. So I said here, the travel time between each pair of stops is random. This means that if we observe the bus, Starting from stop A, driving to stop B, This time will be different if we observe it in different time… at different times. So for day one, I… I use a clock to, record the traveling time from A to B. It's 10 minutes. And for day 2, it might be 10 minutes plus 30 seconds. And the next day, the day 3, will be 9 minutes and 45 seconds. So every time when we try to measure the traveling time between each pair of the stops, it will be slightly different. It is not a constant. So in this case, we can say that this component is ran… So for those, say, traffic jams. then the travel time between stop A and B will be very, very long. Right? Whereas, if for one day, if the driver, drives the bus, Very fast. Then… The traveling time will be quite short. And this time will also affect the number of people waiting at the stop B. Suppose there is a traffic jam, so it takes super long time to drive from A, stop A to stop B, then we would expect that the number of passengers waiting at stop B will be more than the usual case. When the buzz just, Drive in an ordinary speed. So, the number of waiting passengers at stop B is also random. And also, at each stop, the number of passengers getting off is also random. So, say if we, take that bus, and we take that bus for several times. We count the number of people who get off at bus stop B. But every time this number will be slightly different, it cannot be… always be the constant, like, every time it's 5 people who are getting off. Usually, there will be certain variation, like, 3 people today. 5 people next day, 4 people on day 3, something like that. And actually, for this random component, we can use the random variables to describe their behaviors. So first, it's about the travel time. The bus travel time between each pair of the stops is modeled as a random variable. Drawn from a normal distribution. So we know for normal distribution, It's a bell-shaped, It's symmetric. And the probability that the, if we regard the, maybe let me… That me… A lot. Let me change the device. Okay, so for normal distribution, Suppose this is time t. This is… F15. So this, travel time, we regard it, follows a normal distribution. Say the traveling time from stop A and stop B On average, it's 10 minutes. So the probability that the traveling time is between Baby. Between here and here. So suppose this is, like, 9. 2… This is 10.8 minutes. The probability that the traveling time is between 9.2 to 10.8 minutes the… the probability. is very high. So you can see the area is very large. Compared to the case where the driving time between, say, 11 to 12, Then this variability is very small. So we can use this, normal distribution to… to describe the traveling time. So most of the time, the traveling time will be between, say, 9.2 to 10.8. Then, with the mean, which is the 10 minute here. And the standard deviation, so suppose this represents the, 3 standard deviation. Here is 0.8, then I have roughly, this is, like, 0.2… Sixth? Right. So I have this standard deviation, Estimated from sample data. Specifically, we use the API, we can collect the estimated time of arrival. At each stop for 30 trips of bus number 56. So I know… from this, ETA data, so this is the real-time, arrival time. a record the number it takes from stop A to stop B for 30 times. And I use the average of the travel time of the 30 times as the mean. Of my normal distribution. And I also use the standard deviation of this 30, traveling times as the standard deviation of my normal distribution. So then, in each simulation, I can draw a random number from this specific normal distribution. as the travel time from stop A to stop B. So every time, the travel time will be different. Because it is drawn from a normal distribution. But they are drawn from the same distribution. Where the mean and standard deviation is estimated based on, the, Via real-time data. And then, we calculate the mean and standard deviation of travel times between each pair of stops. For each simulation run, we sample travel times from the corresponding normal distributions. To represent the bus travel times between stops. So if there are different pair of stops. So for this pair of stops, each time I will draw a, travel time, from… A normal distribution with same mean equals to 10, variance equals to 0.3. Whereas for the next pair of bus stops. Because the distance between these two might be different from the previous pair of stations. So, I may need to draw the traveling time from a normal distribution with, say, mean value 15. And 0.2, something like that. So for each pair of There's bus stops. I would draw this travel time from normal distribution whose mean and standard deviation is estimated from the ETA data. If we implement it in code, it will be, the random.normal. We use numpy mp.random.normal. These command will help us to draw the random numbers from normal distribution with specific mean and specific standard deviation. So after we know the traveling time. Between each pair of the bus stops. And we know that this will affect the number of waiting passengers at stop B. Because, as mentioned, the longer the traveling time, the larger number of waiting passengers. And this number of waiting passengers is often used… is often described by this so-called poison distribution. So Poisson distribution is a discrete distribution. So it can only take… It can only take value, like, 0 or 1 or 2 or 3. And it can be used to describe the number of events happened within a unit's time interval. Say, we want to describe the number of passengers, waiting at a stop. Or the number of customers go into a supermarket, So this is… about counting. The number of events happened. And if we know that it follows a poison distribution, then one of the key parameters So parameter is just like the mean and standard deviation for a normal distribution. For poison distribution, the key parameter is lambda. It represents the average number of occurrence in the time interval. So suppose we know that if lambda equals to 4, It means, on average, In one hour. There will be 4 people waiting at bus stop. Then, we can calculate the corresponding probability when there is, like, only Zero people waiting at the bus stop. Then we know the average number is 4, then… If we calculate the probability of zero passengers. Or waiting at that bus stop, the corresponding probability will be very low. And it is also, makes sense that if the average number of passengers waiting at the bus stop Within the unit time, interval is 4, then the probability that During that time interval, there will be 5 people who are waiting at the bus stop. The probability of this event will be relatively high. Because… On average, there will be 4 people waiting there. And 5 people is close to… to the average, close to the… Four people. So then the chance of There are 5 people waiting there, this probability should be relatively high. So you can observe this, graph. When the average is 4, then the probability of 5 people waiting there is relatively high, whereas If we know, on average, there will be 4 people waiting there. The probability that there will be 20 people waiting there, then… The likelihood of this event will be relatively small. So that is the shape of this poison distribution. And then… Just like what we did for the traveling time, we need to estimate the lambda. The average number of people waiting at different bus stops. And this can be estimated by the field observation. Say, now we are at the bus stop 2. And suppose, imagine that we are on the bus, Starting from stop 1. We start to see how long it takes To drive from stop 1 to stop 2, And it turns out that The travel time is 10 minutes. And at stop 2, there are 5 people waiting there. This is our first observation. Then, for the next day, or for the next shift. The traveling time between stop 1 and stop 2 is 15 minutes. And then we observe there are 8 people. We are waiting at stop 2. So we have a record, so on and so forth. So after we collected this field data. We can calculate the rate for each observation. So the rate represents the average number of passengers In the time interval. So you may imagine that the passengers just come, In a uniformly way. So during this 10 minutes, In total, there are 5 people. Catch the… Arrive at stop 2. So this means, on average, for every minute, There are 0.5 people. Arrived at the stop tool. Similarly, we can calculate this arrival rate For, the next few observations. And then we can take average of these rates As an estimate of the average number of passengers waiting at stop 2. Say, if we only have these 4 observations on average, for every minute. 0.51 passengers will arrive at Stock 2. And with this estimation, for each time of the simulation. We can draw a random number of passengers. from a Poisson distribution with lambda equals to this 0.5. But, of course, we need to time the, time interval of the traveling time. So this lambda rate is… per minute, How many passengers will come? And these need to be multiplied by the time interval of traveling from stop 1 to stop 2. So this is about how we, Simulate the number of waiting passengers. And then… the passengers must get off somewhere, right? They cannot, like, stay in the bus forever. There is another distribution, which is called the binomial distribution. That can be used to describe the number of passengers getting off at each stop. So for this distribution, you may just regard it as If we flip a coin for several times, say, 20 times. And we care the number of times that we get a hassle. It gets a heads up. So, say, I do the experiment, I flip a fair coin for 20 times. Then, for this experiment, it turns out that there are 8 Coins. That are heads up. So this is one observation. And we can repeat this experiment. And the event that we are interested is the number of Heads up, off the coin. And we record the number of heads up in the sequence of, flip, this coin flipping. So here, you may just regard those passengers who get off as the coin has a heads up. So we just… Regarding the total number of coin flipping as the number of people on the bus. And then we count how many people get off. So the number of get-offs is the event that we are interested. And then… The difference between the coin flipping and the passengers get off is that we know for a fair coin. The probability of having a heads-up is 50%. Right. But here, we actually don't know. How many percent of the people will get off? And this probability will be different for different stops. say, for those stops that are near the MTR station, then it's more likely that the passenger will get off at that station, because they want to take MTR. Whereas for those small stations, then… Overall, the number of people who get off the bus will be… will be Will be fewer, will be smaller, right? So then we can estimate the probability of getting off for each stop, again, using the field data. So we collect data over several days or weeks, and again, we have certain observations for the specific stop. So for stop 2, originally there are 10 people on the bus. And it turns out that 4 of them are light. For the next observation, in total, there are 12 people Riding on the bus. And at stop 2, 5 of them are light. So on and so forth. So we can use these observations To estimate the probability of a light lighting, For each stop. Using this example, at stop 2, The probabilities of getting off will be 0.4, 0.42, 0.4. These are all the observations for a specific stop, Then we can take average. Say we can take average as 0.4 and regard this as the probability of getting off. For this specific stop. And later in the simulation, we will draw the number of passengers getting off, from… the pool of… The number of passengers on the bus. So these passengers depends on the number of people waiting at stop 2, And also the, The… the passengers who… Get on the bus at stop 1, So this is our pool of passengers. And for this group of passengers, The probability of alighting the bus. Will be the probability that is estimated from the, field observations. So for all the passengers on the bus. With the probability of a light. Being estimated by the field data. We can draw a random number of how many of the passengers will get off at a specific stop. So that's the three random components in our simulation. And to implement this simulation, we will make use of the Python library, which is called SynPy. So, SimPai is a discrete event simulation framework. And it is specifically designed to model the system where events happened at discrete points in time. Then what does an event mean? So the event represents a specific action. For example, when the bus Start to drive. Or when the bus arrives at a stop, Or when passengers start Boarding, and bus departure, a stop after a certain dwell time. So these are, so-called events happened. And these events are processed in a chromological order according to their scheduled time. And only when they occur. So, say, during the time interval between the bus driving from stop A and stop B, Even though the time passed, So recall that in the visualization, there is a clock, right? The time just keep pass, Keep passing, but the event will be paused because there's no event happens. There's no, there's no action that changed The status of the overall, system. And only when the event happens, like bus arrives, passenger get on board, when this event happens, then we record the time of this event. And later in the demo, Jupyter Notebook, you can see a typical Sympi structure, including these four steps. So, first of all, we will create a simple environment. So we use this, environment, we use… you will see this command. And second step is to define a generator function. So to generate the, the process that we… we are interested. So we have the bus trip. And the arguments can include many, many scenarios. So the first must be the environment, we just compute. And then we can consider, if we run the simulation for many, many times, then we can record this number of simulations, so we can record This round number. And also, if there are different bus buses on the simulation, we can record the bus ID, and then track the behavior of different buses. Then we can also, specify the road configuration. Say, about the forward direction, it passed through, the bus passed through, those 11 stops. Whereas at the return direction, it will pass another 10 stops. So we can put the road configuration in this generator function. And also, save the passenger data. Say how many people get on, how many people get off. So these are all the possible components or arguments in this generator function. And also, as mentioned, for the discrete event simulation. For the time gap between two events, we need to pause the process, For those, Time interval between events. So we will yield this yield. Comment, environment time out for, say, the travel time. For the travel time, because nothing special happened, We will not, like, use the… the resources. We, we just… Pause the process, but let the time pass. Then, we can add the generator function to the Sympi environment. So you will see int.process, you will see this key, function name. And we put… The defined generator function here. And then, the last step is to run the simulation and to let the time pass. So, environment.run. So this is how we execute the simulation, by processing all the scheduled events until completion. And you'll always see this environment.nel. It means we record the current time when an event happens. So to have a, intuitive understanding, maybe we go back to the demo drop your notebook. So, as mentioned, we have this week 4 demo Shook your notebook. It's called the, Week 4 Devo. So the first part is just show how to use this NumPy to generate, random variables. Like, we set a random seed, so every time the random numbers you generate it will be the same. And it's actually quite simple, just use… numpy.random.normal. And by defining the, The mean and standard deviation, and how many random numbers you want, you can Generate the, corresponding result. And again, we can visualize the simulated random numbers. So this is normally distributed. If we plot the, histogram, and also the, box and whisker plot. So hopefully by now, you, you are clear about the meaning of this fox and whisper plot. These two should be quite consistent. And then we can go to this four-step structure to set up a simulation using Simply. As mentioned, the first step is to create a simple environment, and here we just do the simulation for a fixed traveling time from stop A to stop B. In this case, we defined the generator function. And we first record the, departure time. And then the bus will travel for 3 minutes. And because for the 3 minutes, it's not an event. We just pause the process and use yield, To record the timeout, And then, after 3 minutes. The time passes. The bus arrives at stop speed. Then we, again, record the current time, which is the arrival time, Then we'll print it out. And then for step 3, we add the generator function to a simple environment. So this is environmental process. If we run it, Oops. I think I should have run the… previous cell. Yep. The bus process added to the environment. And then the step 4 is to run the simulation and let time pass. So if I run it, it says bus departs at time 0, bus arrives at time 3, simulation completed. Finally, the time is 3. So that is a very simple simulation of just driving the bus from stop A to stop B. But later, we can add more elements, as discussed, into this framework. To, simulate more complicated scenarios. Let's have a 10-minute break first. Okay, let's resume. So for this code, Don't worry that you don't have to start from scratch, you just ask the AI assistant of what kind of simulation you want to have. and add those random components one by one, and I think, the, GitHub compiler can handle this scale of simulation. So I will use the next around 10 minutes, 10 to 15 minutes, to finish the demonstration and also the remaining slides. So previously, we just set the very basic simulation for just a bus traveling from stop A to stop B. Now, we add a random travel time and run the simulation for 100 times. So instead of a fixed traveling time, 3 minutes, we add certain randomness. We have a list to store our results of the traveling time. Then here, we first define the generating… generator function. And later, we follow the remaining steps. So now, for the generator function, instead of the environment, we will record the run number. Because we have, we will have 100 simulations, so we need to have a placeholder for the number of simulations. At the beginning, it's the same. We record the departure time, and then we create random travel time from a normal distribution with mean equals to 3 and standard deviation equals to 0.3. So this is exactly what we did for the first part, which is the random number generation. Here, we have this maximum function to ensure that the value we draw from the normal distribution must be positive. Because this is travel time, it must be non-negative. But if we really randomly drawn from a normal distribution like this. Although the probability of drawing a negative value is very, very, very, very small, but still, it is possible. And to avoid that situation, we use this max function to, to set the 0.1 as the lower bound. If the travel time is lower than the 0.1, we will use the 0.1 as our travel time. Then, during the travel time, the process will be paused. And then we record the arrival time and print out that the bus arrived at a certain time. Then we gradually append our results to the, to the… to the big list about the running number, the departure time, the arrival time, so on and so forth. So, start from here, we, use a loop, tool… To implement the 100, simulations. So, again, step one, create the environment. Step two, we define the generator function, which is the upper part. And then step 3, we add the generator function to a SynPy environment. Now here, for this process, we have two arguments, the environment and also the number of simulations. Then we ask the, the SimPai to help us to execute the simulations. Then print the result. And the result will… will look like this. So for run 1, bus departures at… Time 0, and arrivals at times 3.2. So every time, for every run of simulation, you can see that the arrival time will be different, will be slightly different. So this time, it's drawn from a normal distribution with mean 3 and variance No, standard deviation, 0.3. Okay, so if you want to read more results, you can click this scrollable element. So it will show all the, 100 times of the simulation results. Now we come back to the slice. Let me share a screen again. Right. So after we implement the assimilation, we can get the results. So recall that our KPI for this project is the ute, sorry, it's the seed utilization rate. So for each stop, we record the, we, we… Use this box and whisker plot to show the distribution of the… in 1,000 times the seed utilization rate for each stock. So this is the, the existing scenario. And the direction is forward, so from Qinmen to Shengshui. And we can see that with the, driving of this bus setting out. The seed utilization rate increases, So again, this orange vertical bar represents the median. from… 12% to around 34%. And here, for this station, this is Shenzhui MTR exit. So you can observe there is a drop of the seat utilization rate, which makes sense, because people take bus all along… all along the way to get to the MTR station. And then, finally, all the passengers get off at the last station. So for this trip, the median of the seed utilization is around 12 to 34 across different stops. And because, on average, this Distribution shows a slightly right-skilled, because there are many, outliers on the right-hand side. So the mean value is expected to be a little bit higher compared to these orange bars. So if we take average, it will be around… Sirty… 30-something. So, 30-something. So that is the existing… Utilization rate across these different stocks. Similarly, we can calculate the median of seat utilization for the return direction. And these circled 3 stops are new. But we can still observe them, because the stops are there. We can use the field data, as mentioned, use the field data to To estimate the traveling time, to estimate the number of people waiting at different stops, and also the number of people getting off the bus. And we can also, based on certain assumption of the removed stops. So for these two stops, they are no longer there, and we have no way to Track the historical data of the number of passengers, getting on, getting off. So these are based on certain assumptions. We may use the number of passengers waiting at the neighboring stops as the number of passengers waiting at those stops. And regarding the traveling time, we can find the distance of this routine estate to the original bus stop, then have an estimate of the traveling time. So to generate the before adjustments, we need certain assumptions of the traveling time and passenger flow. And if the assumptions are correct, then… Based on the simulation results, the median of the seed utilization rate will be between 18% to 56%. So comparing to the existing scenario, before the adjustment is done, then the seat utilization rate is indeed higher. Compared to… compared to the situation when the bus frequency is adjusted. Similarly, we can calculate or estimate the median of seat utilization for the return direction and before the adjustment. So, the results summary, Is that the adjustment appears to have reduced the overall seat utilization rate. But with the increase of the frequency of bus, the cost of the bus company must also increase. Right? So, within one hour, there will be one more bus to… to operate, and there must be the captain to drive the bus. And also, the… the funeral, will… will be a cost. So, if we consider the cost, then it is a problem, or it is a question that whether the, the income Produced by this bus frequency increase. Whether it can cover the cost. Of the, frequency increase of the bus. So then we can, formulate the inquiry to the transport department based on our analysis. So first, what type of operational and passenger flow data, like the stop level boarding and a light peak And off-peak passenger accounts were collected and analyzed when assessing the rerouting and schedule change for this bus number 56. So you notice that in our simulation. Some data are collected by ourselves. And some of them are estimated based on very limited data. They say we need to count the number of people waiting there, we need to count the number of people alight the bus. But whether this work, has systematically done by TD. As a review of the adjustment of the… of 50… 56. So this is unclear. But we can ask whether this type of data is available, whether it is already collected and analyzed. And second is, what quantitative models or criteria were used to evaluate whether the service modification would maintain Or improve the passenger service quality. So what exactly criteria they use to evaluate whether this is a, group, this is a good adjustment. And in what sense? Say, the city utilization rate decreased. But on the other hand, from the perspective of the bus company. So that may increase the cost. Then, how… what kind of index they use to evaluate whether this modification is, is overall a good move or not. And also, whether the relevant operational data sets, the consultation summaries, or evaluation models are available for public or academic review. If these datasets are already there, then can we access to it so that it can save us the time to collect the data by ourselves, and also improve the data quality? Because… what we can do is just collecting very limited data based on our availability, but if the TD conducted that field study, maybe it is more systematic, the number of data points will be more than ours. So that will improve our model parameter estimation, so that it will increase the accuracy of our simulation. We want to know whether such data is available to be accessed. And if not, would the TD consider releasing or try to summarize the data based on the code on access to information? So this is the second, case study. So hopefully, through this case study, you have a taste of, how we can use simulations to quantitatively measure or predict the system behavior of the index we are interested in here, like the seat utilization rate. And in your own group project, if your focus is on the public transportation, you may also need to apply similar simulation technique into your study.

**Simon Wang:** Okay, so, so, Talia, maybe, allow me to jump in and, just to… offer kind of a high-level, summary, especially for students, with limited math background, and, you know, some of the technical details may be a little bit, overwhelming to you, but, I'm… I've only offered kind of, like, a layman's account on what we're trying to do here. So, basically. But when we do simulation, we are using, mass models, to try to approximate and try to get as close as we can an account of the reality, right? And because of the limited amount of data that we have. it's not possible to… to actually grasp, or to… to actually understand the reality, or have a very precise, descriptive account of the reality. So, So instead of, trying to get that, we, we use the simulation approach. So that's kind of the general, kind of picture, what we're trying to do here. And as we are using, the math model, of course, we have to select different math models, right? There's the… The first one, we're talking about using the normal distribution, and then there's the binomial model, and then there's the poison.

**Tian WU:** listening.

**Simon Wang:** model for… for different, scenarios and different kind of, descriptions. So… so that's where we, we probably need some inputs from the experts. We have to consult the, the experts on… on this. But then at the same time, in order to have a, a good approximation or simulation, we also need some real data, right? So we can't just do simulation without any real data. That's why we have to go to the field. In fact, the master students who did this project, actually, they went to the site, and they collected some data, like when… how many passengers get off and get on the bus, and some real data we have to collect it. And with that real data fed into the model, we will have a model that can actually provide the kind of approximation or simulation for us to better understand the reality. So… so that's why, you know, next week or the week after, you need to also think about whether you can collect some field data. But one thing we have to acknowledge is that we are very small teams, right? We are doing a course project, so it's not possible for us to do any kind of large-scale data collection. But the government, the government has got much more resources, you know? If they decide it is important to collect some data and then use the simulation to better understand the reality, to better make decisions. Then they can actually make the decision to collect more data. So that's where the data governance practices and data governance evaluation becomes very important and relevant here. So our job, you know, when we do our project, is to look at, you know, what data has been collected and curated by the government team, and whether or not this kind of data could be used for simulation. That can help us better understand the reality. So, most likely, the government team is not necessarily doing that. You know, the data they've got may be very limited, or they've got the data, but they've never done any simulation. to help them make decisions. Then that's our opportunity to make the argument, to say, look, you know, there's actually a better way to make decisions. So if you got the data, if you collect just a small amount of data with reasonable, you know, resources, then we will be able to build a model, we're going to do the simulation that can help us to make better decisions. So I hope that you can keep this in mind. And of course, you know, there's the more technical details, and the AI can help you to write the code, to run the simulation, but more importantly, you need to know why. Why are we doing this? So, so I hope that that can sort of clarify things a bit, but of course, When… in the context of the specific project that we are working on, then we have to decide which model is the most appropriate and relevant for doing the simulation. Right.

**Tian WU:** Yeah, I think for the remaining time, we'll work on the in-class exercise, too. But there are only 3 tasks, so hopefully it's more straightforward than last times. A tip is that when you use the GitHub Copilot, you can make use of the Ghost test. If you remember, for example, now you can see my… You can see my notebook, right? I put my cursor at the end of the comment, starts with this hash, And if I hit enter. There will be such so-called ghost text showing up. So if you think it's okay, then you hit the tab button. You don't have to, like, ask every question in the chat box. So sometimes the, the ghost attacks is already good enough. You may consider to use this. Rather than ask everything to GitHub Copilot using this chat box. Yep, so after I hit the enter button, some… some… Command just shows up. If you think it's correct, it is consistent with your requirement. I said set the random seed at 48, but now it's set as 42, which is not right. But I can, I can change it. Yep. And for 20 times, so we need to generate the, random variables for 20 times, and print… to print it out. So you can… Modify the, the, requirement, you want the, GitHub Copilot to do using this hash, and then just Say… I don't know why it keeps generating log normal distribution, but it should be poison distribution. maybe I set these sentences one by one so that it can perform as what I expect. Let me play with this. Oops. Yeah, I think Simon just set out some rooms. He's setting some rooms. for questions, If you need help, you can go into the, specific room, We have, in total. For, teaching staff. David. Lili… I think Lily is here. Yeah, Simon and me. So if you have specific questions about this in-class exercise. Or any questions regarding the course material, feel free to join the room and ask questions to us.

**Simon Wang:** Right, so, yeah, so there's four rooms, and if any of them, any of us are helping other students, you can either wait, or you can try another room. And what was the deadline of this in-class exercise?

**Tian WU:** So far, I think I set it as… Let me see. 2… 15.9.

**Simon Wang:** Okay, so because I think… I don't know whether, whether most of the students are at home, you know. just in case, if they need a bit more time, I think we can be a bit more flexible here, but let's see how… because I think the exercise today is actually not very difficult, so maybe we'll see how it goes. Okay, so yeah, so I will see you in the breakout room, or if you have any questions, you can also send a message to the WhatsApp group, okay?